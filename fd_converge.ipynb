{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "focal-centre",
   "metadata": {},
   "source": [
    "# Setup and libraries\n",
    "\n",
    "We'll import the usual libraries and improve on the default plotting resolution done within notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For plotting in jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-outside",
   "metadata": {},
   "source": [
    "# Function and point of interest\n",
    "\n",
    "Consider the function \n",
    "\n",
    "$$f(x) = \\cos(x)\\sin(x)\\sqrt{x}$$\n",
    "\n",
    "Suppose we'd like to estimate its derivative at a point of interest, denoted $x_0 = 1.5$. Let's do the following\n",
    "* Write a python function that computes $f(x)$ given an input (potentially a 1D array of grid points) $x$.\n",
    "* Define a variable for the point of interest\n",
    "* Plot the function $f(x)$ and point of interest $x_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to differentiate\n",
    "f = lambda x: np.cos(x)*np.sin(x)*np.sqrt(x)\n",
    "\n",
    "# Define point of interest x0\n",
    "x0 = 1.2\n",
    "\n",
    "# Plot the function and the evaluation point\n",
    "xmin = x0 - 0.5\n",
    "xmax = x0 + 0.5\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "plt.plot(x, f(x), label='Function')\n",
    "plt.plot(x0, f(x0), 'r.', markersize=15, label=r'$x_0$')\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title(r'Function behavior near $x_0$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-billion",
   "metadata": {},
   "source": [
    "# Numerical derivatives\n",
    "\n",
    "Next we'll compute the numerical derivative at $x_0$ using two schemes:\n",
    "1. Forward difference\n",
    "2. Central difference\n",
    "\n",
    "The code below is set up to compute the derivative using step sizes of $h = \\dfrac{1}{2^2}, \\dfrac{1}{2^3}, ..., \\dfrac{1}{2^{12}}$. This way, we can plot the convergence behvior as we change the step size $h$.\n",
    "\n",
    "Try changing the <code>plt.plot</code> calls below to <code>plt.semilogx</code> to better observe the convergence behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define h as a 1D array of step sizes: h = [1/4, 1/8, 1/16, ..., 1/(2^n)]\n",
    "n = np.arange(2., 13., 1) # 'arange' does not include endpoint\n",
    "h = 2**(-n)\n",
    "\n",
    "# Compute forward difference scheme for each value of h\n",
    "fdiff = (f(x0 + h) - f(x0))/h\n",
    "    \n",
    "# Compute central difference scheme for each value of h\n",
    "cdiff = (f(x0 + h) - f(x0 - h))/(2*h)\n",
    "\n",
    "# Plot derivative values as a function of 'h' to see convergence\n",
    "plt.plot(h,fdiff,'o-',label='Forward difference')\n",
    "plt.plot(h,cdiff,'o-',label='Central difference')\n",
    "plt.grid()\n",
    "plt.xlabel('Step size h')\n",
    "plt.ylabel('Numerical derivative value')\n",
    "plt.title('Derivative convergence behavior')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-amber",
   "metadata": {},
   "source": [
    "# Error behavior\n",
    "\n",
    "Next, we'd like to track the error convergence behavior of each scheme. Since we know the analytical expression for the function, we can compare the derivative estimates to the exact derivative.\n",
    "\n",
    "The exact derivative of $f(x)$ is \n",
    "\n",
    "$$f'(x) = \\dfrac{\\cos(x)\\sin(x)}{2\\sqrt{x}} + (\\cos^2{x} - \\sin^2{x})\\sqrt{x}$$\n",
    "\n",
    "The error in a derivative at a point $x_0$ is defined as \n",
    "\n",
    "$$|\\tau(x_0)| = |f_{true}'(x_0) - f'_{scheme}(x_0)|$$\n",
    "\n",
    "In this case, $f'_{scheme}$ is either the forward difference or central difference scheme \n",
    "\n",
    "## Error convergence rate\n",
    "\n",
    "As discussed in class, the error in a finite difference scheme scheme is always related to step size $h$ as \n",
    "\n",
    "$$|\\tau| = O(h^\\alpha)$$\n",
    "\n",
    "This means that for sufficiently small $h$, \n",
    "\n",
    "$$\\tau \\approx Ch^\\alpha$$\n",
    "\n",
    "Taking the logarithm (any base) of either side leads to\n",
    "\n",
    "$$\\log{|\\tau|} = \\alpha\\log{h} + C$$\n",
    "\n",
    "We therefore expect to see a linear relationship between the log of absolute error vs log $h$, with a slope of $\\alpha$. \n",
    "\n",
    "In the code below, we\n",
    "1. Plot the relationship between log of absolute error vs log of $h$ for each scheme\n",
    "2. Estimate the slope of each line using slope $\\approx \\dfrac{\\Delta y}{\\Delta x}$ between successive data points. This is easily accomplished by using the <code>np.diff</code> function, which calculates the change $\\Delta$ between successive entries in an array.\n",
    "\n",
    "Review the print statements about the slope of each graph - does it match your expectations for these schemes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True derivative of the function\n",
    "fprime = lambda x: 0.5*np.cos(x)*np.sin(x)/np.sqrt(x) + np.sqrt(x)*(-np.sin(x)**2 + np.cos(x)**2)\n",
    "\n",
    "# Compute errors from finite difference approximations, |tau|\n",
    "tau_fdiff = abs(fprime(x0) - fdiff)\n",
    "tau_cdiff = abs(fprime(x0) - cdiff)\n",
    "\n",
    "# Plotting\n",
    "plt.loglog(h, tau_fdiff, 'o-', label='Forward Difference error')\n",
    "plt.loglog(h, tau_cdiff, 'o-', label='Central Difference error')\n",
    "plt.xlabel('h')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Derivative error behavior')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compute log values of step size and error\n",
    "xdata = np.log(h)\n",
    "ydata_fdiff = np.log(tau_fdiff)\n",
    "ydata_cdiff = np.log(tau_cdiff)\n",
    "\n",
    "# Estimate the slop of the forward difference data (log error vs log h)\n",
    "fdiff_slope = np.diff(ydata_fdiff)/np.diff(xdata)\n",
    "print('Forward Difference slope = ', fdiff_slope)\n",
    "\n",
    "# Estimate the slop of the central difference data (log error vs log h)\n",
    "cdiff_slope = np.diff(ydata_cdiff)/np.diff(xdata)\n",
    "print('Central Difference slope = ', cdiff_slope)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
